import { NextRequest, NextResponse } from "next/server";
import { HfInference } from "@huggingface/inference";
import { tmpdir } from "os";
import path from "path";
import { promisify } from "util";
import fs from "fs";

// export const config = {
//   api: {
//     bodyParser: {
//       sizeLimit: '50mb'
//     },
//     responseLimit: false
//   }
// };

let ffmpeg: any;
if (process.env.NODE_ENV === 'production') {
  const ffmpegPath = require('@ffmpeg-installer/ffmpeg').path;
  ffmpeg = require('fluent-ffmpeg');
  ffmpeg.setFfmpegPath(ffmpegPath);
} else {
  const ffmpegPath = require('@ffmpeg-installer/ffmpeg').path;
  ffmpeg = require('fluent-ffmpeg');
  ffmpeg.setFfmpegPath(ffmpegPath);
}

const writeFile = promisify(fs.writeFile);
const unlink = promisify(fs.unlink);
const readFile = promisify(fs.readFile);

console.log("üöÄ Initializing HuggingFace client...");
if (!process.env.HUGGINGFACE_API_KEY) {
  console.error('‚ùå API Route: HUGGINGFACE_API_KEY is not set in environment variables');
  throw new Error('HUGGINGFACE_API_KEY is not configured');
}
const hf = new HfInference(process.env.HUGGINGFACE_API_KEY!);
console.log("‚úÖ HuggingFace client initialized");

async function fetchWithTimeout(url: string, timeout: number) {
  console.log("‚è≥ Starting fetch with timeout:", timeout);
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), timeout);

  try {
    const response = await fetch(url, {
      signal: controller.signal,
    });
    clearTimeout(timeoutId);
    console.log("‚úÖ Fetch completed successfully");
    return response;
  } catch (error) {
    clearTimeout(timeoutId);
    console.error("‚ùå Fetch failed:", error);
    throw error;
  }
}

async function cleanupFiles(...files: string[]) {
  console.log("üßπ Starting cleanup of files:", files);
  for (const file of files) {
    try {
      if (fs.existsSync(file)) {
        await unlink(file);
        console.log(`‚úÖ Cleaned up file: ${file}`);
      }
    } catch (error) {
      console.error(`‚ùå Error cleaning up file ${file}:`, error);
    }
  }
}

async function transcribeAudio(audioBuffer: Buffer): Promise<string> {
  console.log("üéØ Starting transcription with HuggingFace...");
  try {
    
    const formData = new FormData();
    const audioBlob = new Blob([audioBuffer], { type: 'audio/mp3' });
    formData.append('audio', audioBlob, 'audio.mp3');

    
    const response = await fetch(
      `https://api-inference.huggingface.co/models/openai/whisper-large-v3`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.HUGGINGFACE_API_KEY}`
        },
        body: formData
      }
    );

    if (!response.ok) {
      throw new Error(`HuggingFace API error: ${response.status} ${response.statusText}`);
    }

    const result = await response.json();
    console.log("‚úÖ Transcription completed", result);
    return result.text;

  } catch (error) {
    console.error("‚ùå Transcription error:", error);
    throw new Error(`Transcription failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
}

async function generateSummary(text: string, maxRetries = 3): Promise<string> {
  console.log(`ü§ñ Starting summary generation (max retries: ${maxRetries})`);
  console.log(`üìù Text length to summarize: ${text.length} characters`);
  
  let attempt = 0;
  while (attempt < maxRetries) {
    try {
      console.log(`‚è≥ Summary attempt ${attempt + 1}/${maxRetries}`);
      const summary = await hf.summarization({
        model: "facebook/bart-large-cnn",
        inputs: text,
        parameters: {
          max_length: 130,
          min_length: 30,
          do_sample: false
        }
      });
      
      console.log("‚úÖ Summary generated successfully");
      return summary.summary_text;
    } catch (error) {
      attempt++;
      console.error(`‚ùå Summary attempt ${attempt} failed:`, error);
      
      if (attempt === maxRetries) {
        console.error("‚ùå All summary attempts exhausted");
        throw new Error(`Failed to generate summary after ${maxRetries} attempts`);
      }
      
      await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
    }
  }
  throw new Error("Failed to generate summary");
}

export async function POST(req: NextRequest) {
  console.log("\nüé¨ Starting new transcription request...");
  const videoPath = path.join(tmpdir(), `temp-${Date.now()}.mp4`);
  const audioPath = path.join(tmpdir(), `temp-${Date.now()}.mp3`);

  try {
    const { videoUrl } = await req.json();
    console.log("üìå Video URL received:");

    if (!videoUrl) {
      return NextResponse.json(
        { error: "Video URL is required" },
        { status: 400 }
      );
    }

    // Download video
    const videoResponse = await fetchWithTimeout(videoUrl, 30000);
    if (!videoResponse.ok) {
      throw new Error(
        `Failed to download video: ${videoResponse.status} ${videoResponse.statusText}`
      );
    }

    // Save video file
    const buffer = await videoResponse.arrayBuffer();
    await writeFile(videoPath, new Uint8Array(buffer));
    console.log("‚úÖ Video file saved");

    // Convert to audio with optimal settings for Whisper
    await new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .toFormat("mp3")
        .audioChannels(1)          
        .audioFrequency(16000)     
        .audioBitrate('64k')       
        .on("error", (err: Error) => {
          console.error("‚ùå FFmpeg error:", err);
          reject(new Error(`Audio conversion failed: ${err.message}`));
        })
        .on("end", () => {
          console.log("‚úÖ Audio conversion completed");
          resolve(true);
        })
        .save(audioPath);
    });

    // Read and verify audio file
    const audioData = await readFile(audioPath);
    if (audioData.length === 0) {
      throw new Error("Generated audio file is empty");
    }
    console.log(`‚úÖ Audio file read: ${audioData.length} bytes`);

    // Transcribe
    const transcriptionText = await transcribeAudio(audioData);
    
    // Clean the transcription text
    const cleanedText = transcriptionText
      .replace(/\s+/g, ' ')
      .trim();
    console.log("‚úÖ Transcription cleaned");

    let summary = null;
    if (cleanedText.length > 0) {
      try {
        summary = await generateSummary(cleanedText);
      } catch (error) {
        console.error("‚ùå Summary generation failed:", error);
      }
    }

    return NextResponse.json({
      transcription: cleanedText,
      summary: summary || "Summary generation failed",
    });

  } catch (error) {
    console.error("‚ùå Process failed with error:", error);
    return NextResponse.json(
      { 
        error: "Transcription failed", 
        details: error instanceof Error ? error.message : "Unknown error" 
      },
      { status: 500 }
    );

  } finally {
    await cleanupFiles(videoPath, audioPath);
  }
}

export async function GET() {
  return NextResponse.json({ error: "Method not allowed" }, { status: 405 });
}
